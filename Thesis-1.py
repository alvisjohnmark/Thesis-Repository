# -*- coding: utf-8 -*-
"""thesis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1guek7hcD1FUHGWupyYLDC5r7w1VEm2Db
"""

# Importing required libraries
# Keras
# sklearn
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Other
import librosa
import librosa.display
import json
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pyplot import specgram
import pandas as pd
import seaborn as sns
import glob
import os
import pickle
import IPython.display as ipd  # To play sound in the notebook
from google.colab import drive
from sklearn.preprocessing import MinMaxScaler, StandardScaler
drive.mount('/content/drive/', force_remount=True)

"""# Data exploration"""

path_audio = '/content/drive/MyDrive/thesis/audio/'
data = '/content/drive/MyDrive/thesis/audio_dataset.csv'
# data = {
#     'path': [path_audio + str(i) + '.wav' for i in range(1, 21)],
#     'label': [0,1,2,3,0,1,2,3,0,1,2,3,0,1,2,3,0,1,2,3]
# }
data = pd.read_csv(data)
df = pd.DataFrame(data)

def createPath(code):
  return path_audio + str(code) + '.mp3'
df['path'] = df['Code'].apply(createPath)
df.drop('Code', axis=1, inplace=True)

ipd.Audio(filename=df['path'][2])

lb = LabelEncoder()
d = lb.fit_transform(df['Label'])
df['label'] = d
df.drop('Label', axis=1, inplace=True)
df

classes_dict = {
    0: 'Happy',
    1: 'Angry',
    2: 'Sad',
    3: 'Calm'
}

df

"""# Remove missing audio files"""

import os.path
def isFileExists(path):
  try:
    y, sr = librosa.load(path, res_type='soxr_lq',duration=1 ,sr=22050 ,offset=5)
  except:
    df.drop(df[df['path'] == path].index, inplace=True)

df.shape

"""# Feature extraction"""

def extract_features(data, sample_rate):

    result = np.array([])

    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)
    result = np.hstack((result, mfcc))
    # print("mfcc: ", len(mfcc))

    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate, hop_length=20, n_mels=128).T, axis=0)
    result = np.hstack((result, mel))
    # print("mel: ", len(mel))

    stft = np.abs(librosa.stft(data))
    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
    result = np.hstack((result, chroma_stft))
    # print("chrome: ", len(chroma_stft))

    rolloff = librosa.feature.spectral_rolloff(y=data, sr=sample_rate)[0]
    result = np.hstack((result, rolloff))
    # print("rolloff: ", len(rolloff))

    spec_bw = librosa.feature.spectral_bandwidth(y=data, sr=sample_rate)[0]
    result = np.hstack((result,spec_bw))
    # print("spec_bw: ", len(spec_bw)

    contrast = librosa.feature.spectral_contrast(y=data)[0]
    result = np.hstack((result, contrast))
    # print("contrast: ", len(contrast))

    flatness = librosa.feature.spectral_flatness(y=data)[0]
    result = np.hstack((result, flatness))
    # print("flatness: ", len(flatness))

    cent = librosa.feature.spectral_centroid(y=data, sr=sample_rate)[0]
    result = np.hstack((result, cent))

    rms =  librosa.feature.rms(y=data, frame_length=100)[0]
    result = np.hstack((result, rms))
    # print("rms: ", len(rms))

    tempo, _ = librosa.beat.beat_track(y=data, sr=sample_rate)
    result = np.hstack((result, tempo))
    # print("tempo: ", len(tempo))

    zcr = librosa.feature.zero_crossing_rate(y=data)[0]
    result = np.hstack((result, zcr))
    # print("zcr: ", len(zcr))

    return result

def feature_extractor(path):
    data, sample_rate = librosa.load(path, duration=25 ,sr=22050*2 ,offset=3)
    res1 = extract_features(data, sample_rate)
    result = np.array(res1)
    return result

p = feature_extractor(df['path'][0])
p.shape

#this is to remove data that has no audio file
for index, (data, emotion) in enumerate(zip(df["path"], df["label"])):
  if index % 20 == 0:
      print("#", end="")
  try:
    y, sr = librosa.load(data, duration=1 ,sr=10 ,offset=3)
  except:
    df.drop(df[df['path'] == data].index, inplace=True)
    continue

X, y = [], []
for index, (data, emotion) in enumerate(zip(df["path"], df["label"])):
    feature = feature_extractor(data)
    X.append(feature)
    y.append(emotion)
    if index % 20 == 0:
        print("#", end="")

X = np.array(X)
dataframe = pd.DataFrame(data = X[1:, 0:],
                         columns = X[0, 0:])
dataframe["label"] = y[1:]
dataframe.head()

"""# Data analysis"""

# file = '/content/drive/MyDrive/thesis/audio_features_25_soxrHQ_22.csv'
file = '/content/drive/MyDrive/thesis/audio_features_25_soxrHQ_44_dominant_all_stacked_169.csv'

df2 = pd.read_csv(file)

# df_second = pd.read_csv(file)

"""## Mean"""

audio_features = [
    (range(0, 40), 'MFCC'),
    (range(40, 168), 'Mel-Frequency'),
    (range(168, 180), 'Chroma'),
    (range(180, 181), 'Spectral Rolloff'),
    (range(181, 182), 'Spectral Bandwidth'),
    (range(182, 183), 'Spectral Contrast'),
    (range(183, 184), 'Spectral Flatness'),
    (range(184, 185), 'Spectral Centroid'),
    (range(185, 186), 'RMS'),
    (range(186, 187), 'Tempo'),
    (range(187, 188), 'ZCR'),
    (range(188, 189), 'Label'),
]
col_names = []
for feature_range, feature_name in audio_features:
    col_names.extend([f"{feature_name}_{i}" for i in feature_range])

df2.columns = col_names
df2

X = df2.rename(columns=lambda col: col.rsplit('_', 1)[0])
X = X.groupby(axis=1, level=0).mean()
X

sns.pairplot(X, hue="Label")

"""# Segmentation"""

path_audio_full = '/content/drive/MyDrive/thesis/audio/songofruth.mp3'

def segment_audio(audio, sr, seconds, overlap):
    if seconds <= 0 or overlap < 0 or seconds <= overlap:
        raise ValueError("Invalid seconds or overlap parameters.")
    seconds = int(seconds * sr)
    overlap = int(overlap * sr)
    step = seconds - overlap
    segments = []

    for i in range(0, len(audio) - seconds + 1, step):
        segments.append(audio[i:i + seconds])

    # Optional: Include the last partial segment if needed
    # if (len(audio) - seconds) % step != 0 and len(audio) > seconds:
    #     segments.append(audio[-seconds:])

    return segments



def getSegments():

    y, sr = librosa.load(path_audio_full ,sr=22050*2)
    y, _ = librosa.effects.trim(y)
    # y = np.arange(401000 * 25)  # Example signal
    # sr = 40100               # 22 kHz sampling rate
    seconds = 5       # seconds per segment
    overlap = 2   # seconds overlap
    print(len(y))
    return segment_audio(y, sr, seconds, overlap)

segments = getSegments()
segments

X = []
for i, data in enumerate(segments):
    segment = extract_features(data, 22050 * 2)
    X.append(segment)

X = np.array(X)
dataframe = pd.DataFrame(data = X, columns = [str(x) for x in range(1, X.shape[1] + 1)])
dataframe.head()

dataframe.shape

#predict: call to predict a segment

X_predict = []

# | code | predicted |
step = 5 # the seconds
for i in range(0, len(df), step):
  song = df.iloc[i:i + step]
  for segment in song:
    result = 0
    print(segment)
    X_predict.append(result)


X_predict = np.array(X_predict)
dataframe = pd.DataFrame(data = X, columns = ['code', 'predicted'])
dataframe.head()

path = '/content/drive/MyDrive/thesis/dataset/songofruth_segments.csv'
with open(path, 'w', encoding = 'utf-8-sig') as f:
  dataframe.to_csv(f)